{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import concurrent.futures\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import numpy\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize multiple LLM clients\n",
    "clients = [\n",
    "    OpenAI(base_url=\"http://localhost:123/v1\", api_key=\"sk_1234567890\"),\n",
    "    OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"sk_1234567890\"),\n",
    "    OpenAI(base_url=\"http://localhost:12345/v1\", api_key=\"sk_1234567890\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BOOL_SYSTEM_MESSAGE = \"\"\"You are excellent message moderator, expert in detecting fraudulent messages.\n",
    "\n",
    "You will be given \"Messages\" and your job is to predict if a message is fraudulent or not.\n",
    "\n",
    "You ONLY respond FOLLOWING this json schema:\n",
    "\n",
    "{\n",
    "    \"is_fraudulent\": {\n",
    "        \"type\": \"boolean\",\n",
    "        \"description\": \"Whether the message is predicted to be fraudulent.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "You MUST ONLY RESPOND with a boolean value in JSON. Either true or false in JSON. NO EXPLANATIONS OR COMMENTS.\n",
    "\n",
    "Example of valid responses:\n",
    "{\n",
    "    \"is_fraudulent\": true\n",
    "}\n",
    "or \n",
    "{\n",
    "    \"is_fraudulent\": false\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\AI-PROJECT-LUISS\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Define multiple clients for different model instances\n",
    "clients = {\n",
    "    \"model1\": OpenAI(base_url=\"http://localhost:123/v1\", api_key=\"sk_1234567890\"),\n",
    "    \"model2\": OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"sk_1234567890\"),\n",
    "    \"model3\": OpenAI(base_url=\"http://localhost:12345/v1\", api_key=\"sk_1234567890\")\n",
    "}\n",
    "\n",
    "BOOL_SYSTEM_MESSAGE = \"\"\"[Your system message as before]\"\"\"\n",
    "\n",
    "system_message = BOOL_SYSTEM_MESSAGE\n",
    "\n",
    "def predict_fraudulence_modified(client, sms_text):\n",
    "    # Similar to your original function, but now uses the client passed as an argument\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": sms_text},\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "        )\n",
    "        prediction_content = response.choices[0].message.content\n",
    "        try:\n",
    "            prediction_json = json.loads(prediction_content)\n",
    "            if \"is_fraudulent\" in prediction_json and type(prediction_json[\"is_fraudulent\"]) == bool:\n",
    "                return prediction_json['is_fraudulent'], 'valid'\n",
    "            else:\n",
    "                # Record the raw response if JSON is invalid but well-formed\n",
    "                return prediction_content, 'invalid_json'\n",
    "        except json.JSONDecodeError:\n",
    "            # Record the raw response if JSON structure is invalid\n",
    "            return prediction_content, 'invalid_json_structure'\n",
    "    except Exception as e:\n",
    "        return str(e), 'error'\n",
    "\n",
    "def process_batch(client_key, df_subset):\n",
    "    for index, row in df_subset.iterrows():\n",
    "        sms_text = row['SMS test']  # Make sure the column name matches your dataset\n",
    "        predicted_label, prediction_type = predict_fraudulence_modified(clients[client_key], sms_text)\n",
    "        df_subset.at[index, 'Predicted'] = predicted_label\n",
    "        df_subset.at[index, 'PredictionType'] = prediction_type\n",
    "    # Save partial results for each subset\n",
    "    df_subset.to_csv(f'../dataset/sms_predictions_{client_key}.csv', index=False)\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('../dataset/sms.csv')\n",
    "    df['Predicted'] = None\n",
    "    df['PredictionType'] = None\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Splitting the dataset into three parts\n",
    "df_parts = np.array_split(df, 3)\n",
    "\n",
    "# Create and start threads for parallel processing\n",
    "threads = []\n",
    "for i, client_key in enumerate(clients.keys()):\n",
    "    thread = threading.Thread(target=process_batch, args=(client_key, df_parts[i]))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "# Combine the parts back into a single DataFrame\n",
    "df_final = pd.concat([pd.read_csv(f'../dataset/sms_predictions_{client_key}.csv') for client_key in clients.keys()])\n",
    "\n",
    "# Calculate and print metrics\n",
    "valid_predictions_df = df_final[df_final['PredictionType'] == 'valid']\n",
    "accuracy = accuracy_score(valid_predictions_df['Fraudulent'], valid_predictions_df['Predicted'])\n",
    "precision = precision_score(valid_predictions_df['Fraudulent'], valid_predictions_df['Predicted'])\n",
    "recall = recall_score(valid_predictions_df['Fraudulent'], valid_predictions_df['Predicted'])\n",
    "f1 = f1_score(valid_predictions_df['Fraudulent'], valid_predictions_df['Predicted'])\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
